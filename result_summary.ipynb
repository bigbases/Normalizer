{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” '/home/Normalizer/Proposed/logs/DDN' ê²½ë¡œì—ì„œ ë¡œê·¸ íŒŒì¼ íƒìƒ‰ì„ ì‹œì‘í•©ë‹ˆë‹¤...\n",
      "\n",
      "âœ… ì‘ì—… ì™„ë£Œ! ê²°ê³¼ê°€ 'experiment_cost_times.csv' íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "--- ìƒì„±ëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° ---\n",
      "     model data   pl   cost_time\n",
      "0  DLinear  tra  720  111.527186\n",
      "1  DLinear  elc  720   33.999058\n",
      "2  DLinear  wea  720   21.497741\n",
      "3  DLinear  em2  336    9.276879\n",
      "4  DLinear  eh2  336    1.619305\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Union\n",
    "\n",
    "# ì´ì „ ë‹¨ê³„ì—ì„œ ì‘ì„±í•œ cost time ê³„ì‚° í•¨ìˆ˜ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "def calculate_average_cost_time(file_path: str) -> Union[float, None]:\n",
    "    \"\"\"\n",
    "    ë¡œê·¸ íŒŒì¼ì—ì„œ ì²« 5ê°œ ì—í¬í¬ì˜ í‰ê·  cost timeì„ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    cost_times = []\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                if line.strip().startswith('Epoch:') and 'cost time:' in line:\n",
    "                    try:\n",
    "                        time_str = line.split('cost time:')[1].strip()\n",
    "                        cost_time = float(time_str)\n",
    "                        cost_times.append(cost_time)\n",
    "                        if len(cost_times) == 5:\n",
    "                            break\n",
    "                    except (IndexError, ValueError):\n",
    "                        continue\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ì˜¤ë¥˜: '{file_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return None\n",
    "\n",
    "    if len(cost_times) < 5:\n",
    "        # ê²½ê³  ë©”ì‹œì§€ëŠ” ë„ˆë¬´ ë§ì´ ì¶œë ¥ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì£¼ì„ ì²˜ë¦¬í•˜ê±°ë‚˜ í•„ìš”ì‹œ í™œì„±í™”\n",
    "        # print(f\"ê²½ê³ : '{file_path}'ì—ì„œ 5ê°œ ì—í¬í¬ë¥¼ ëª¨ë‘ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤ (ì°¾ì€ ê°œìˆ˜: {len(cost_times)}).\")\n",
    "        return None\n",
    "    \n",
    "    return sum(cost_times) / len(cost_times)\n",
    "\n",
    "def process_logs_to_csv(root_path: str, output_csv_path: str) -> None:\n",
    "    \"\"\"\n",
    "    ì§€ì •ëœ ê²½ë¡œì˜ ëª¨ë“  í•˜ìœ„ í´ë”ì™€ ë¡œê·¸ íŒŒì¼ì„ íƒìƒ‰í•˜ì—¬ cost timeì„ ì¶”ì¶œí•˜ê³  CSVë¡œ ì €ì¥í•©ë‹ˆë‹¤.\n",
    "\n",
    "    Args:\n",
    "        root_path (str): ë¡œê·¸ í´ë”ë“¤ì´ ìˆëŠ” ìµœìƒìœ„ ê²½ë¡œ.\n",
    "        output_csv_path (str): ê²°ê³¼ë¥¼ ì €ì¥í•  CSV íŒŒì¼ ê²½ë¡œ.\n",
    "    \"\"\"\n",
    "    all_results: List[Dict[str, Union[str, float]]] = []\n",
    "\n",
    "    print(f\"ğŸ” '{root_path}' ê²½ë¡œì—ì„œ ë¡œê·¸ íŒŒì¼ íƒìƒ‰ì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "\n",
    "    # root_path ë°”ë¡œ ì•„ë˜ì— ìˆëŠ” ëª¨ë“  í•­ëª©ì„ ìˆœíšŒ (ì´ê²ƒë“¤ì´ model í´ë”ê°€ ë¨)\n",
    "    if not os.path.isdir(root_path):\n",
    "        print(f\"ì˜¤ë¥˜: '{root_path}'ëŠ” ìœ íš¨í•œ ë””ë ‰í„°ë¦¬ê°€ ì•„ë‹™ë‹ˆë‹¤.\")\n",
    "        return\n",
    "\n",
    "    for model_name in os.listdir(root_path):\n",
    "        model_path = os.path.join(root_path, model_name)\n",
    "\n",
    "        # í´ë”ì¸ ê²½ìš°ì—ë§Œ ì²˜ë¦¬\n",
    "        if os.path.isdir(model_path):\n",
    "            # í•´ë‹¹ ëª¨ë¸ í´ë” ì•ˆì˜ ëª¨ë“  íŒŒì¼ì„ ìˆœíšŒ\n",
    "            for filename in os.listdir(model_path):\n",
    "                if filename.endswith('.log'):\n",
    "                    # íŒŒì¼ ì´ë¦„ì—ì„œ í™•ì¥ì(.log) ì œê±°\n",
    "                    base_name = os.path.splitext(filename)[0]\n",
    "                    \n",
    "                    # '_'ë¥¼ ê¸°ì¤€ìœ¼ë¡œ íŒŒì¼ ì´ë¦„ ë¶„ë¦¬\n",
    "                    parts = base_name.split('_')\n",
    "                    if len(parts) == 2:\n",
    "                        data, pl = parts[0], parts[1]\n",
    "                        \n",
    "                        log_file_path = os.path.join(model_path, filename)\n",
    "                        \n",
    "                        # cost time ê³„ì‚°\n",
    "                        cost_time = calculate_average_cost_time(log_file_path)\n",
    "                        \n",
    "                        # cost_timeì´ ì„±ê³µì ìœ¼ë¡œ ê³„ì‚°ëœ ê²½ìš°ì—ë§Œ ê²°ê³¼ì— ì¶”ê°€\n",
    "                        if cost_time is not None:\n",
    "                            result_row = {\n",
    "                                'model': model_name,\n",
    "                                'data': data,\n",
    "                                'pl': pl,\n",
    "                                'cost_time': cost_time\n",
    "                            }\n",
    "                            all_results.append(result_row)\n",
    "    \n",
    "    if not all_results:\n",
    "        print(\"ì²˜ë¦¬í•  ë¡œê·¸ íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. íŒŒì¼ êµ¬ì¡°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
    "        return\n",
    "\n",
    "    # ê²°ê³¼ë¥¼ pandas DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "    df = pd.DataFrame(all_results)\n",
    "    \n",
    "    # DataFrameì„ CSV íŒŒì¼ë¡œ ì €ì¥ (ì¸ë±ìŠ¤ëŠ” ì €ì¥í•˜ì§€ ì•ŠìŒ)\n",
    "    df.to_csv(output_csv_path, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    print(f\"\\nâœ… ì‘ì—… ì™„ë£Œ! ê²°ê³¼ê°€ '{output_csv_path}' íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    print(\"--- ìƒì„±ëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° ---\")\n",
    "    print(df.head())\n",
    "\n",
    "\n",
    "# --- ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ë¶€ë¶„ ---\n",
    "if __name__ == \"__main__\":\n",
    "    # â— ì—¬ê¸°ì— ì‹¤ì œ ë¡œê·¸ íŒŒì¼ë“¤ì´ ìˆëŠ” ìƒìœ„ í´ë” ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”.\n",
    "    # ì˜ˆ: \"C:/Users/MyUser/Documents/Experiments/logs\"\n",
    "    root_directory = \"/home/Normalizer/Proposed/logs/DDN\"  # í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ì˜ˆì‹œ ê²½ë¡œ\n",
    "\n",
    "    # ê²°ê³¼ë¥¼ ì €ì¥í•  CSV íŒŒì¼ ì´ë¦„\n",
    "    output_csv_file = \"experiment_cost_times.csv\"\n",
    "\n",
    "    # ë©”ì¸ í•¨ìˆ˜ ì‹¤í–‰\n",
    "    process_logs_to_csv(root_directory, output_csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë¡œê·¸ íŒŒì¼ '/home/Normalizer/Proposed/logs/DDN/iTransformer/elc_336.log' ë¶„ì„ ê²°ê³¼:\n",
      "----------------------------------------\n",
      "  - 1~5 ì—í¬í¬ ì†Œìš”ì‹œê°„ í•©ê³„  : 238.3324ì´ˆ\n",
      "  - 6 ì—í¬í¬ ì´í›„ ì†Œìš”ì‹œê°„ í•©ê³„ : 916.4257ì´ˆ\n",
      "  - ì´ ì—í¬í¬ ì†Œìš”ì‹œê°„ í•©ê³„    : 1154.7582ì´ˆ\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from typing import Dict, Union\n",
    "\n",
    "def calculate_epoch_time_sums(file_path: str) -> Union[Dict[str, float], None]:\n",
    "    \"\"\"\n",
    "    ë¡œê·¸ íŒŒì¼ì—ì„œ ì—í¬í¬ë³„ cost timeì„ êµ¬ê°„ë³„ë¡œ í•©ì‚°í•©ë‹ˆë‹¤.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): ë¶„ì„í•  ë¡œê·¸ íŒŒì¼ì˜ ê²½ë¡œ\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, float] | None: ì„¸ ê°€ì§€ í•©ê³„ê°€ ë‹´ê¸´ ë”•ì…”ë„ˆë¦¬.\n",
    "                                 íŒŒì¼ì„ ì°¾ì§€ ëª»í•˜ë©´ Noneì„ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    # í•©ê³„ë¥¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬ ì´ˆê¸°í™”\n",
    "    sums = {\n",
    "        \"sum_first_five_epochs\": 0.0,\n",
    "        \"sum_after_five_epochs\": 0.0,\n",
    "        \"total_sum_all_epochs\": 0.0\n",
    "    }\n",
    "    \n",
    "    # Epoch ìˆ«ìì™€ cost timeì„ í•œ ë²ˆì— ì¶”ì¶œí•˜ê¸° ìœ„í•œ ì •ê·œí‘œí˜„ì‹\n",
    "    # (Station, Backbone ì ‘ë‘ì‚¬ë¥¼ ì„ íƒì ìœ¼ë¡œ ì²˜ë¦¬)\n",
    "    epoch_pattern = re.compile(r\"(?:Station |Backbone )?Epoch: (\\d+).*cost time: ([\\d.]+)\")\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                match = epoch_pattern.search(line)\n",
    "                if match:\n",
    "                    try:\n",
    "                        epoch_num = int(match.group(1))\n",
    "                        cost_time = float(match.group(2))\n",
    "                        \n",
    "                        # 1. ì „ì²´ í•©ê³„ì— ìš°ì„  ë”í•˜ê¸°\n",
    "                        sums[\"total_sum_all_epochs\"] += cost_time\n",
    "                        \n",
    "                        # 2. êµ¬ê°„ë³„ í•©ê³„ ê³„ì‚°\n",
    "                        if epoch_num <= 5:\n",
    "                            sums[\"sum_first_five_epochs\"] += cost_time\n",
    "                        else:\n",
    "                            sums[\"sum_after_five_epochs\"] += cost_time\n",
    "                            \n",
    "                    except (ValueError, IndexError):\n",
    "                        # ì •ê·œì‹ê³¼ ë§¤ì¹­ë˜ì—ˆìœ¼ë‚˜ ìˆ«ì ë³€í™˜ì— ì‹¤íŒ¨í•œ ê²½ìš° (ê±°ì˜ ë°œìƒí•˜ì§€ ì•ŠìŒ)\n",
    "                        continue\n",
    "                        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"ì˜¤ë¥˜: '{file_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return None\n",
    "\n",
    "    return sums\n",
    "\n",
    "# --- ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ë¶€ë¶„ ---\n",
    "if __name__ == \"__main__\":\n",
    "    # â— ì—¬ê¸°ì— ì‹¤ì œ ë¶„ì„í•˜ê³  ì‹¶ì€ .log íŒŒì¼ì˜ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”.\n",
    "    log_file_path = '/home/Normalizer/Proposed/logs/DDN/iTransformer/elc_336.log'\n",
    "\n",
    "    # ë©”ì¸ í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë°›ìŠµë‹ˆë‹¤.\n",
    "    time_sums = calculate_epoch_time_sums(log_file_path)\n",
    "\n",
    "    # ê²°ê³¼ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "    if time_sums:\n",
    "        print(f\"âœ… ë¡œê·¸ íŒŒì¼ '{log_file_path}' ë¶„ì„ ê²°ê³¼:\")\n",
    "        print(\"-\" * 40)\n",
    "        print(f\"  - 1~5 ì—í¬í¬ ì†Œìš”ì‹œê°„ í•©ê³„  : {time_sums['sum_first_five_epochs']:.4f}ì´ˆ\")\n",
    "        print(f\"  - 6 ì—í¬í¬ ì´í›„ ì†Œìš”ì‹œê°„ í•©ê³„ : {time_sums['sum_after_five_epochs']:.4f}ì´ˆ\")\n",
    "        print(f\"  - ì´ ì—í¬í¬ ì†Œìš”ì‹œê°„ í•©ê³„    : {time_sums['total_sum_all_epochs']:.4f}ì´ˆ\")\n",
    "        print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('result.csv')\n",
    "result_list = []\n",
    "for i in range(len(df)):\n",
    "    settings = df.Setting[i].split('_')\n",
    "    dataset = settings[1]\n",
    "    model_name = settings[4]\n",
    "    seq_len = settings[7][2:]\n",
    "    pred_len = settings[9][2:]\n",
    "    station_lr = settings[-3][3:]\n",
    "    use_mlp = settings[-2][2:]\n",
    "    mse = df.MSE[i]\n",
    "    mae = df.MAE[i]\n",
    "    \n",
    "    result_list.append([dataset, model_name, seq_len, pred_len, station_lr, use_mlp, mse, mae])\n",
    "df_result = pd.DataFrame(result_list, columns=['Dataset', 'Model', 'Seq_Len', 'Pred_Len', 'Station_LR', 'Use_MLP', 'MSE', 'MAE'])\n",
    "df_result.to_csv('summary_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
